{
  
    
        "post0": {
            "title": "JavaScript demo",
            "content": "output using HTML and CSS . Multiple cells are used to setup HTML in this lesson. Many of the JavaScript cells will use the output tag(s) to write into the HTML that has been setup. . %%html is used to setup HTML code block | &quot;style&quot; tag enables visuals customization | &quot;div&quot; tag is setup to receive data | . %%html &lt;html&gt; &lt;head&gt; &lt;style&gt; #output { background-color: #353b45; padding: 10px; border: 3px solid #ccc; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;output&quot;&gt; Hello! &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; . evalmachine.&lt;anonymous&gt;:1 %%html ^ SyntaxError: Unexpected token % at new Script (vm.js:79:7) at createScript (vm.js:251:10) at Object.runInThisContext (vm.js:303:10) at run ([eval]:1020:15) at onRunRequest ([eval]:864:18) at onMessage ([eval]:828:13) at process.emit (events.js:182:13) at emit (internal/child_process.js:812:12) at process._tickCallback (internal/process/next_tick.js:63:19) . output explored . There are several ways to ouput the classic introduction message: &quot;Hello, World!&quot; . Before you go further, open Console on your Browser. JavaScript developer leaves Console open all the time!!! | The function console.log() outputs to Console, this is often used for inspection or debugging. | &quot;Hello, World&quot; is a String literal. This is the referred to as Static text, as it does not change. Developer call this a hard coded string. | &quot;Hello, World&quot; literal is a parameter to console.log(), element.txt() and alert(). | The element.txt function is part of Jupyter Notebook %%js magic. This is convenient for Notebook and testing. | The alert command outputs the parameter to a dialog box, so you can see it in this Jupyter notebook. The alert commands are shown, but are commented out as the stop run all execution of the notebook. | Note, in a Web Application Debugging: An alert is often used for less savy Developers. Console is used by more savy developers; console often requires setting up a lot of outputs. Source level debugging is the most powerful solution for debugging and does not require alert or console commands. | . %%js // required to allow cell to be JavaScript enabled console.log(&quot;JavaScript/Jupyter Output Intro&quot;); // Browser Console output; debugging or tracing console.log(&quot;Hello, World!&quot;); console.log(&quot;Hello, World Again!&quot;); // Document Object Model (DOM) output; output to HTML, CSS which is standard for a Web Page // &lt;mark&gt;select element method&lt;/mark&gt;: DOM native JavaScript get, document.getElementByID document.getElementById(&quot;output&quot;).textContent = &quot;Hello, World!&quot;; // &lt;mark&gt;jQuery CSS-style method&lt;/mark&gt;: Tag for DOM selector, $(&#39;#output&#39;) $(&#39;#output&#39;).append(&#39;&lt;br&gt;&lt;b&gt;Hello World Again!&#39;); // br is break or new line, b is bold // Jupyter built in magic element for testing and convenience of development element.text(&quot;Hello, World!&quot;); // element is output option as part of %%js magic element.append(&#39;&lt;br&gt;&lt;b&gt;Hello World Again!&#39;); //alert(&quot;Hello, World!&quot;); . multiple outputs using one variable . This second example is a new sequence of code, two or more lines of code forms a sequence. This example defines a variable, thank goodness!!! In the previous example we were typing the string &quot;Hello, World&quot; over and over. Observe with the variable msg=&quot;Hello, World!&quot;; we type the string once and now use msg over and over. . The variable &quot;var msg =&quot; is used to capture the data | The console.log(msg) outputs to console, be sure to Inspect it! | The element.text() is part of Jupyter Notebooks and displays as output blow the code on this page. Until we build up some more interesting data for Web Site, we will not use be using the Python HTML, CSS technique. | The alert(msg) works the same as previous, but as the other commands uses msg as parameter. | . %%js console.log(&quot;Variable Definition&quot;); var msg = &quot;Hello, World!&quot;; // Use msg to output code to Console and Jupyter Notebook console.log(msg); //right click browser select Inspect, then select Console to view element.text(msg); //alert(msg); . output showing use of a function . This example passes the defined variable &quot;msg&quot; to the newly defined &quot;function logIt(output)&quot;. . There are multiple steps in this code.. The &quot;definition of the function&quot;: &quot;function logIt(output) {}&quot; and everything between curly braces is the definitions of the function. Passing a parameter is required when you call this function. | The &quot;call to the function:&quot;logIt(msg)&quot; is the call to the function, this actually runs the function. The variable &quot;msg&quot; is used a parameter when calling the logIt function. | . | Showing reuse of function... There are two calls to the logIt function | This is called Prodedural Abstraction, a term that means reusing the same code | . | . %%js console.log(&quot;Function Definition&quot;); /* Function: logIt * Parameter: output * Description: The parameter is &quot;output&quot; to console and jupyter page */ function logIt(output) { console.log(output); element.append(output + &quot;&lt;br&gt;&quot;); //alert(output); } // First sequence calling logIt function var msg = &quot;Hello, World!&quot;; logIt(msg); // Second sequence calling logIt function var msg = &quot;Hello, &lt;b&gt;Students&lt;/b&gt;!&quot; // replaces content of variable var classOf = &quot;Welcome CS class of 2023-2024.&quot; logIt(msg + &quot; &quot; + classOf); // concatenation of strings . output showing Loosely typed data . JavaScript is a loosely typed language, meaning you don&#39;t have to specify what type of information will be stored in a variable in advance. . To define a variable you prefix the name with var or const. The variable type is determined by JavaScript at runtime. | Python and many interpretive languages are loosely typed like JavaScript. This is considered programmer friendly. | Java which is a compiled language is strongly typed, thus you will see terms like String, Integer, Double, and Object in the source code. | In JavaScript, the typeof keyword returns the type of the variable. Become familiar with type as it is valuable in conversation and knowing type help you understand how to modify data. Each variable type will have built in methods to manage content within the data type. | . %%js console.log(&quot;Examine Data Types&quot;); // Function to add typeof to output function getType(output) { return typeof output + &quot;: &quot; + output; } // Function defintion function logIt(output) { console.log(getType(output)); // logs string console.info(output); // logs object element.append(getType(output) + &quot;&lt;br&gt;&quot;); // adds to Jupyter output //alert(getType(output)); } // Common Types element.append(&quot;Common Types &lt;br&gt;&quot;); logIt(&quot;Mr M&quot;); // String logIt(1997); // Number logIt(true); // Boolean element.append(&quot;&lt;br&gt;&quot;); // Object Type, this definition is often called a array or list element.append(&quot;Object Type, array &lt;br&gt;&quot;); var scores = [ 90, 80, 100 ]; logIt(scores); element.append(&quot;&lt;br&gt;&quot;); // Complex Object, this definition is often called hash, map, hashmap, or dictionary element.append(&quot;Object Type, hash or dictionary &lt;br&gt;&quot;); var person = { // key:value pairs seperated by comma &quot;name&quot;: &quot;Mr M&quot;, &quot;role&quot;: &quot;Teacher&quot; }; logIt(person); logIt(JSON.stringify(person)); //method used to convert this object into readable format . Build a Person object and JSON . JavaScript and other languages have special properties and syntax to store and represent data. In fact, a class in JavaScript is a special function. . Definition of class allows for a collection of data, the &quot;class Person&quot; allows programmer to retain name, github id, and class of a Person. | Instance of a class, the &quot;const teacher = new Person(&quot;Mr M&quot;, &quot;jm1021&quot;, 1977)&quot; makes an object &quot;teacher&quot; which is an object representation of &quot;class Person&quot;. | Setting and Getting properties After creating teacher and student objects, observe that properties can be changed/muted or extracted/accessed. | . %%html &lt;!-- load jQuery and tablesorter scripts --&gt; &lt;html&gt; &lt;head&gt; &lt;!-- load jQuery and tablesorter scripts --&gt; &lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.31.3/js/jquery.tablesorter.min.js&quot;&gt;&lt;/script&gt; &lt;style&gt; /* CSS-style selector maps to table id or other id&#39;s in HTML */ #jsonTable, #flaskTable { background-color: #353b45; padding: 10px; border: 3px solid #ccc; box-shadow: 0.8em 0.4em 0.4em grey; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- Table for writing and extracting jsonText --&gt; &lt;table id=&quot;jsonTable&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Classroom JSON Data&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td id=&quot;jsonText&quot;&gt;{&quot;classroom&quot;:[{&quot;type&quot;:&quot;object&quot;,&quot;name&quot;:&quot;sample&quot;,&quot;ghID&quot;:&quot;sample&quot;,&quot;classOf&quot;:2000,&quot;role&quot;:&quot;sample&quot;}]}&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; . . Classroom JSON Data . {&quot;classroom&quot;:[{&quot;type&quot;:&quot;object&quot;,&quot;name&quot;:&quot;sample&quot;,&quot;ghID&quot;:&quot;sample&quot;,&quot;classOf&quot;:2000,&quot;role&quot;:&quot;sample&quot;}]} | . . %%js console.log(&quot;Person objects&quot;); /* class: Person * Description: A collection of Person data */ class Person { /* method: constructor * parameters: name, ghID - GitHub ID, classOf - Graduation Class * description: returns object when &quot;new Person()&quot; is called with matching parameters * assignment: this.name, this.ghID, ... are properties retained in the returned object * default: role uses a default property, it is set to &quot;Student&quot; */ constructor(name, ghID, classOf, role=&quot;Student&quot;) { this.name = name; this.ghID = ghID; this.classOf = classOf; this.role = role; } /* method: setter * parameters: role - role in classroom * description: this.role is updated from default value to value contained in role parameter */ setRole(role) { this.role = role; } /* method: getter * description: turns properties of object into JSON object * return value: JSON object */ getJSON() { const obj = {type: typeof this, name: this.name, ghID: this.ghID, classOf: this.classOf, role: this.role}; const json = JSON.stringify(obj); return json; } /* method: logIT * description: &quot;this&quot; Person object is logged to console */ logIt() { //Person Object console.info(this); //Log to Jupter element.append(&quot;Person object in JSON &lt;br&gt;&quot;); element.append(this.getJSON() + &quot;&lt;br&gt;&quot;); //alert(this.getJSON()); } } // make a new Person Object const teacher = new Person(&quot;Mr M&quot;, &quot;jm1021&quot;, 1977); // object type is easy to work with in JavaScript // update role to Teacher teacher.setRole(&quot;Teacher&quot;); // set the role teacher.logIt(); // log to console // make a new Person Object const student = new Person(&quot;Jane Doe&quot;, &quot;jane&quot;, 2007); // object type is easy to work with in JavaScript student.logIt(); // log to console . Build a Classroom Array/List of Persons and JSON . Many key elements are shown again. New elements include... . Building an Array, &quot;var students&quot; is an array of many persons | Building a Classroom, this show forEach iteration through an array and .push adding to an array. These are key concepts in all programming languages. | . %%js console.log(&quot;Classroom object&quot;); /* class: Person * Description: A collection of Person data */ class Person { /* method: constructor * parameters: name, ghID - GitHub ID, classOf - Graduation Class * description: returns object when &quot;new Person()&quot; is called with matching parameters * assignment: this.name, this.ghID, ... are properties retained in the returned object * default: this.role is a default property retained in object, it is set to &quot;Student&quot; */ constructor(name, ghID, classOf, role=&quot;Student&quot;) { this.name = name; this.ghID = ghID; this.classOf = classOf; this.role = role; } /* method: setter * parameters: role - role in classroom * description: this.role is updated from default value to value contained in role parameter */ setRole(role) { this.role = role; } /* method: getter * description: turns properties of object into JSON object * return value: JSON object */ getJSON() { const obj = {type: typeof this, name: this.name, ghID: this.ghID, classOf: this.classOf, role: this.role}; const json = JSON.stringify(obj); return json; } /* method: logIT * description: &quot;this&quot; Person object is logged to console */ logIt() { //Person Object console.info(this); //Log to Jupter element.append(&quot;Person json &lt;br&gt;&quot;); element.append(this.getJSON() + &quot;&lt;br&gt;&quot;); //alert(this.getJSON()); } } /* class: Classroom * Description: A collection of Person objects */ class Classroom { /* method: constructor * parameters: teacher - a Person object, students - an array of Person objects * description: returns object when &quot;new Classroom()&quot; is called containing properties and methods of a Classroom * assignment: this.classroom, this.teacher, ... are properties retained in the returned object */ constructor(teacher, students) { /* spread: this.classroom contains Teacher object and all Student objects * map: this.json contains of map of all persons to JSON */ this.teacher = teacher; this.students = students; this.classroom = [teacher, ...students]; // ... spread option this.json = &#39;{&quot;classroom&quot;:[&#39; + this.classroom.map(person =&gt; person.getJSON()) + &#39;]}&#39;; } /* method: logIT * description: &quot;this&quot; Classroom object is logged to console */ logIt() { //Classroom object console.log(this); //Classroom json element.append(&quot;Classroom object in JSON&lt;br&gt;&quot;); element.append(this.json + &quot;&lt;br&gt;&quot;); //alert(this.json); } } /* function: constructCompSciClassroom * Description: Create data for Classroom and Person objects * Returns: A Classroom Object */ function constructCompSciClassroom() { // define a Teacher object const teacher = new Person(&quot;Mr M&quot;, &quot;jm1021&quot;, 1977, &quot;Teacher&quot;); // optional 4th parameter // define a student Array of Person objects const students = [ new Person(&quot;Anthony&quot;, &quot;tonyhieu&quot;, 2022), new Person(&quot;Bria&quot;, &quot;B-G101&quot;, 2023), new Person(&quot;Allie&quot;, &quot;xiaoa0&quot;, 2023), new Person(&quot;Tigran&quot;, &quot;Tigran7&quot;, 2023), new Person(&quot;Rebecca&quot;, &quot;Rebecca-123&quot;, 2023), new Person(&quot;Vidhi&quot;, &quot;VidhiKulkarni&quot;, 2024) ]; // make a CompSci classroom from formerly defined teacher and student objects return new Classroom(teacher, students); // returns object } // assigns &quot;compsci&quot; to the object returned by &quot;constructCompSciClassroom()&quot; function const compsci = constructCompSciClassroom(); // output of Objects and JSON in CompSci classroom compsci.logIt(); // enable sharing of data across jupyter cells $(&#39;#jsonText&#39;).text(compsci.json); // posts/embeds/writes compsci.json to HTML DOM element called jsonText . for loop to generate Table Rows in HTML output . This code extracts JSON text from HTML, that was placed in DOM in an earlier JavaScript cell, then it parses text into a JavaScript object. In addition, there is a for loop that iterates over the extracted object generating formated rows and columns in an HTML table. . Table generation is broken into parts... table data is obtained from a classroom array inside of the extracted object. | the JavaScript for loop allows the construction of a new row of data for each Person hash object inside of the the Array. | in the loop a table row &lt;tr&gt; ... &lt;/tr&gt; is created for each Hash object in the Array. | in the loop table data, a table column, &lt;td&gt; ... &lt;/td&gt; is created for name, ghID, classOf, and role within the Hash object. | . | . %%js console.log(&quot;Classroom Web Page&quot;); // extract JSON text from HTML page const jsonText = document.getElementById(&quot;jsonText&quot;).innerHTML; console.log(jsonText); element.append(&quot;Raw jsonText element embedded in HTML&lt;br&gt;&quot;); element.append( jsonText + &quot;&lt;br&gt;&quot;); // convert JSON text to Object const classroom = JSON.parse(jsonText).classroom; console.log(classroom); // from classroom object creates rows and columns in HTML table element.append(&quot;&lt;br&gt;Formatted data sample from jsonText &lt;br&gt;&quot;); for (var row of classroom) { element.append(row.ghID + &quot; &quot; + row.name + &#39;&lt;br&gt;&#39;); // tr for each row, a new line $(&#39;#classroom&#39;).append(&#39;&lt;tr&gt;&#39;) // td for each column of data $(&#39;#classroom&#39;).append(&#39;&lt;td&gt;&#39; + row.name + &#39;&lt;/td&gt;&#39;) $(&#39;#classroom&#39;).append(&#39;&lt;td&gt;&#39; + row.ghID + &#39;&lt;/td&gt;&#39;) $(&#39;#classroom&#39;).append(&#39;&lt;td&gt;&#39; + row.classOf + &#39;&lt;/td&gt;&#39;) $(&#39;#classroom&#39;).append(&#39;&lt;td&gt;&#39; + row.role + &#39;&lt;/td&gt;&#39;) // tr to end row $(&#39;#classroom&#39;).append(&#39;&lt;/tr&gt;&#39;); } . %%html &lt;head&gt; &lt;!-- load jQuery and DataTables scripts --&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.datatables.net/1.10.25/css/jquery.dataTables.min.css&quot;&gt; &lt;script type=&quot;text/javascript&quot; language=&quot;javascript&quot; src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; language=&quot;javascript&quot; src=&quot;https://cdn.datatables.net/1.10.25/js/jquery.dataTables.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;table id=&quot;flaskTable&quot; class=&quot;table&quot; style=&quot;width:100%&quot;&gt; &lt;thead id=&quot;flaskHead&quot;&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;DOB&lt;/th&gt; &lt;th&gt;Age&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody id=&quot;flaskBody&quot;&gt;&lt;/tbody&gt; &lt;/table&gt; &lt;script&gt; $(document).ready(function() { fetch(&#39;https://flask.nighthawkcodingsociety.com/api/users/&#39;, { mode: &#39;cors&#39; }) .then(response =&gt; { if (!response.ok) { throw new Error(&#39;API response failed&#39;); } return response.json(); }) .then(data =&gt; { for (const row of data) { // BUG warning/resolution - DataTable requires row to be single append $(&#39;#flaskBody&#39;).append(&#39;&lt;tr&gt;&lt;td&gt;&#39; + row.id + &#39;&lt;/td&gt;&lt;td&gt;&#39; + row.name + &#39;&lt;/td&gt;&lt;td&gt;&#39; + row.dob + &#39;&lt;/td&gt;&lt;td&gt;&#39; + row.age + &#39;&lt;/td&gt;&lt;/tr&gt;&#39;); } // BUG warning - Jupyter does not show Datatable controls, works on deployed GitHub pages $(&quot;#flaskTable&quot;).DataTable(); }) .catch(error =&gt; { console.error(&#39;Error:&#39;, error); }); }); &lt;/script&gt; . . ID Name DOB Age .",
            "url": "https://xiaoa0.github.io/ds/2023/05/25/js.html",
            "relUrl": "/2023/05/25/js.html",
            "date": " • May 25, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "Natural Language Processing",
            "content": "This notebook runs with the Python 3.9 kernel and can be easily downloaded to run, test, and modify locally. It uses data from a CSV file containing 40000 Amazon reviews. It currently uses text input to predict the score of a given review, but this can be changed by replacing &quot;Score&quot; references to any other column, such as the class names Cat1, Cat2 or Cat3. . 1. Installation . These libraries will need to be installed on the machine to be used later . pip install scikit-learn numpy pandas . Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (1.2.2) Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (1.24.3) Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (2.0.1) Requirement already satisfied: joblib&gt;=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.2.0) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (3.1.0) Requirement already satisfied: scipy&gt;=1.3.2 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.10.1) Requirement already satisfied: tzdata&gt;=2022.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3) Requirement already satisfied: pytz&gt;=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3) Requirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/xiaoa1/Library/Python/3.10/lib/python/site-packages (from pandas) (2.8.2) Requirement already satisfied: six&gt;=1.5 in /Users/xiaoa1/Library/Python/3.10/lib/python/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0) [notice] A new release of pip is available: 23.0.1 -&gt; 23.1.2 [notice] To update, run: python3.10 -m pip install --upgrade pip Note: you may need to restart the kernel to use updated packages. . 2. Import Libraries . This notebook uses numpy, pandas, and scikit-learn for data analysis . import numpy as np import pandas as pd import re from sklearn.utils import shuffle from sklearn.model_selection import train_test_split from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.feature_selection import chi2, SelectKBest from sklearn.svm import LinearSVC . 3. Load and Preprocess Data . The dataset used is train_40k.csv from this Kaggle page. Loading the dataset into a pandas dataframe (df) allows for preprocessing by focusing on relevant columns (review text and rating) so that the data can be cleaned up by removing punctuation. . df_original = pd.read_csv(&#39;/Users/xiaoa1/VSCode/ds/_notebooks/data/train_40k.csv&#39;) columns = [&#39;Text&#39;, &#39;Score&#39;] df = shuffle(df_original[columns]) df.Score.value_counts() p = re.compile(r&#39;[^ w s]+&#39;) df[&#39;Text&#39;] = [p.sub(&#39;&#39;, x) for x in df[&#39;Text&#39;].tolist()] df.apply(lambda x: x.astype(str).str.lower()) . Text Score . 15121 this product has a nice tone and really covers... | 5.0 | . 37624 i placed my order and recieved exactly what i ... | 4.0 | . 32824 these cost 200 from the grocery store no reaso... | 2.0 | . 4019 my 3 12 year old daughter received this as a c... | 2.0 | . 23645 these are great for potty training little boys... | 5.0 | . ... ... | ... | . 13774 definitely not worth all the hype i dont think... | 3.0 | . 22049 this game is a cute boardgame geared towards p... | 4.0 | . 6740 its hard to open even harder to close im afrai... | 1.0 | . 36539 i bought this makeup in nyc at henri bendel ab... | 2.0 | . 22621 cutting sugar out of our dietwe went to splend... | 5.0 | . 40000 rows × 2 columns . 4. Split the Dataset . scikit-learn has a feature to split data for training and testing. The test size and random state can be adjusted to increase accuracy. . x,y = df.Text, df.Score train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=4000) . 5. Building a Pipeline . Pipelines are an iterative way to build a model to accomodate variations in data and improve accuracy. Because datasets can be so large now, its beneficial for data to be sent through a pipeline so that it can be manipulated . pipeline = Pipeline([(&#39;vect&#39;, TfidfVectorizer(ngram_range=(1,2), stop_words=&#39;english&#39;, sublinear_tf=True)), (&#39;chi&#39;, SelectKBest(chi2, k=10000)), (&#39;clf&#39;, LinearSVC(C=1.0, penalty=&#39;l1&#39;,max_iter=3000, dual=False)) ]) . 6. Model Training . This fits the pipeline to our data . model = pipeline.fit(train_x, train_y) . 7. Model Evaluation . Using the score function to rate the accuracy of the model . print(&#39;accuracy score: &#39;+ str(model.score(test_x, test_y))) . accuracy score: 0.647 . 8. Prediction . Now we can use the predict function to input our own written Amazon review and see what the predicted score is! . print(model.predict([&#39;price is good but tasted a bit stale&#39;])) # type your review here to see the predicted rating! exclude punctuation . [4.] .",
            "url": "https://xiaoa0.github.io/ds/2023/05/23/NLP.html",
            "relUrl": "/2023/05/23/NLP.html",
            "date": " • May 23, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "Practice with Pandas, Numpy, Scikit-learn",
            "content": "import matplotlib.pyplot as plt import numpy as np x = np.linspace(0, 2 * np.pi, 200) y = np.sin(x) fig, ax = plt.subplots() ax.plot(x, y) plt.show() . Following this guide for python . import pandas as pd # setting pd as alias mydataset = { # table data &#39;cars&#39;: [&quot;BMW&quot;, &quot;Volvo&quot;, &quot;Ford&quot;], &#39;passings&#39;: [3, 7, 2] } a = [1, 7, 2] myarray = pd.Series(a) mytable = pd.DataFrame(mydataset) # assigning dataset as table to be printed print(myarray) print(myarray[0]) # indexing print(mytable) . 0 1 1 7 2 2 dtype: int64 1 cars passings 0 BMW 3 1 Volvo 7 2 Ford 2 . import pandas as pd # how to print csv file df = pd.read_csv(&#39;data.csv&#39;) print(df) df = pd.read_json(&#39;data.json&#39;) # how to read json file print(df.to_string()) . NumPy is a library used to manage arrays . import numpy as np arr = np.array([1, 2, 3, 4, 5]) print(arr) # arrays can have any # of dimensions &lt;= 0 arr = np.array([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]]) print(arr) print(arr.ndim) # ndim checks dimensions of array print(arr[0, 1]) # index order: row then column . [1 2 3 4 5] [[[1 2 3] [4 5 6]] [[1 2 3] [4 5 6]]] 3 [4 5 6] .",
            "url": "https://xiaoa0.github.io/ds/2023/05/15/pypractice.html",
            "relUrl": "/2023/05/15/pypractice.html",
            "date": " • May 15, 2023"
        }
        
    
  
    
        ,"post3": {
            "title": "Unit 2.3 Extracting Information from Data, Pandas",
            "content": "Files To Get . Save this file to your _notebooks folder . wget https://raw.githubusercontent.com/nighthawkcoders/APCSP/master/_notebooks/2023-03-09-AP-unit2-3.ipynb . Save these files into a subfolder named files in your _notebooks folder . wget https://raw.githubusercontent.com/nighthawkcoders/APCSP/master/_notebooks/files/data.csv . wget https://raw.githubusercontent.com/nighthawkcoders/APCSP/master/_notebooks/files/grade.json . Save this image into a subfolder named images in your _notebooks folder . wget https://raw.githubusercontent.com/nighthawkcoders/APCSP/master/_notebooks/images/table_dataframe.png . Pandas and DataFrames . In this lesson we will be exploring data analysis using Pandas. . College Board talks about ideas like Tools. &quot;the ability to process data depends on users capabilities and their tools&quot; | Combining Data. &quot;combine county data sets&quot; | Status on Data&quot;determining the artist with the greatest attendance during a particular month&quot; | Data poses challenge. &quot;the need to clean data&quot;, &quot;incomplete data&quot; | . | . From Pandas Overview -- When working with tabular data, such as data stored in spreadsheets or databases, pandas is the right tool for you. pandas will help you to explore, clean, and process your data. In pandas, a data table is called a DataFrame. | . . &#39;&#39;&#39;Pandas is used to gather data sets through its DataFrames implementation&#39;&#39;&#39; import pandas as pd . Cleaning Data . When looking at a data set, check to see what data needs to be cleaned. Examples include: . Missing Data Points | Invalid Data | Inaccurate Data | . Run the following code to see what needs to be cleaned . df = pd.read_json(&#39;files/grade.json&#39;) print(df) # What part of the data set needs to be cleaned? # From PBL learning, what is a good time to clean data? Hint, remember Garbage in, Garbage out? . Student ID Year in School GPA 0 123 12 3.57 1 246 10 4.00 2 578 12 2.78 3 469 11 3.45 4 324 Junior 4.75 5 313 20 3.33 6 145 12 2.95 7 167 10 3.90 8 235 9th Grade 3.15 9 nil 9 2.80 10 469 11 3.45 11 456 10 2.75 . Extracting Info . Take a look at some features that the Pandas library has that extracts info from the dataset . DataFrame Extract Column . print(df[[&#39;GPA&#39;]]) print() #try two columns and remove the index from print statement print(df[[&#39;Student ID&#39;,&#39;GPA&#39;]].to_string(index=False)) . GPA 0 3.57 1 4.00 2 2.78 3 3.45 4 4.75 5 3.33 6 2.95 7 3.90 8 3.15 9 2.80 10 3.45 11 2.75 Student ID GPA 123 3.57 246 4.00 578 2.78 469 3.45 324 4.75 313 3.33 145 2.95 167 3.90 235 3.15 nil 2.80 469 3.45 456 2.75 . DataFrame Sort . print(df.sort_values(by=[&#39;GPA&#39;])) print() #sort the values in reverse order print(df.sort_values(by=[&#39;GPA&#39;], ascending=False)) . Student ID Year in School GPA 11 456 10 2.75 2 578 12 2.78 9 nil 9 2.80 6 145 12 2.95 8 235 9th Grade 3.15 5 313 20 3.33 3 469 11 3.45 10 469 11 3.45 0 123 12 3.57 7 167 10 3.90 1 246 10 4.00 4 324 Junior 4.75 Student ID Year in School GPA 4 324 Junior 4.75 1 246 10 4.00 7 167 10 3.90 0 123 12 3.57 3 469 11 3.45 10 469 11 3.45 5 313 20 3.33 8 235 9th Grade 3.15 6 145 12 2.95 9 nil 9 2.80 2 578 12 2.78 11 456 10 2.75 . DataFrame Selection or Filter . print(df[df.GPA &gt; 3.00]) . Student ID Year in School GPA 0 123 12 3.57 1 246 10 4.00 3 469 11 3.45 4 324 Junior 4.75 5 313 20 3.33 7 167 10 3.90 8 235 9th Grade 3.15 10 469 11 3.45 . DataFrame Selection Max and Min . print(df[df.GPA == df.GPA.max()]) print() print(df[df.GPA == df.GPA.min()]) . Student ID Year in School GPA 4 324 Junior 4.75 Student ID Year in School GPA 11 456 10 2.75 . Create your own DataFrame . Using Pandas allows you to create your own DataFrame in Python. . Python Dictionary to Pandas DataFrame . import pandas as pd #the data can be stored as a python dictionary dict = { &quot;calories&quot;: [420, 380, 390], &quot;duration&quot;: [50, 40, 45] } #stores the data in a data frame print(&quot;-Dict_to_DF&quot;) df = pd.DataFrame(dict) print(df) print(&quot;-Dict_to_DF_labels--&quot;) #or with the index argument, you can label rows. df = pd.DataFrame(dict, index = [&quot;day1&quot;, &quot;day2&quot;, &quot;day3&quot;]) print(df) . -Dict_to_DF calories duration 0 420 50 1 380 40 2 390 45 -Dict_to_DF_labels-- calories duration day1 420 50 day2 380 40 day3 390 45 . Examine DataFrame Rows . print(&quot;-Examine Selected Rows&quot;) #use a list for multiple labels: print(df.loc[[&quot;day1&quot;, &quot;day3&quot;]]) #refer to the row index: print(&quot;--Examine Single Row--&quot;) print(df.loc[&quot;day1&quot;]) . -Examine Selected Rows calories duration day1 420 50 day3 390 45 --Examine Single Row-- calories 420 duration 50 Name: day1, dtype: int64 . Pandas DataFrame Information . print(df.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Index: 3 entries, day1 to day3 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 calories 3 non-null int64 1 duration 3 non-null int64 dtypes: int64(2) memory usage: 180.0+ bytes None . Example of larger data set . Pandas can read CSV and many other types of files, run the following code to see more features with a larger data set . import pandas as pd #read csv and sort &#39;Duration&#39; largest to smallest df = pd.read_csv(&#39;files/data.csv&#39;).sort_values(by=[&#39;Duration&#39;], ascending=False) print(&quot;--Duration Top 10&quot;) print(df.head(10)) print(&quot;--Duration Bottom 10&quot;) print(df.tail(10)) . --Duration Top 10 Duration Pulse Maxpulse Calories 69 300 108 143 1500.2 79 270 100 131 1729.0 109 210 137 184 1860.4 60 210 108 160 1376.0 106 180 90 120 800.3 90 180 101 127 600.1 65 180 90 130 800.4 61 160 110 137 1034.4 62 160 109 135 853.0 67 150 107 130 816.0 --Duration Bottom 10 Duration Pulse Maxpulse Calories 68 20 106 136 110.4 100 20 95 112 77.7 89 20 83 107 50.3 135 20 136 156 189.0 94 20 150 171 127.4 95 20 151 168 229.4 139 20 141 162 222.4 64 20 110 130 131.4 112 15 124 139 124.2 93 15 80 100 50.5 . APIs are a Source for Writing Programs with Data . 3rd Party APIs are a great source for creating Pandas Data Frames. . Data can be fetched and resulting json can be placed into a Data Frame | Observe output, this looks very similar to a Database | . &#39;&#39;&#39;Pandas can be used to analyze data&#39;&#39;&#39; import pandas as pd import requests def fetch(): &#39;&#39;&#39;Obtain data from an endpoint&#39;&#39;&#39; url = &quot;https://flask.nighthawkcodingsociety.com/api/covid/&quot; fetch = requests.get(url) json = fetch.json() # filter data for requirement df = pd.DataFrame(json[&#39;countries_stat&#39;]) # filter endpoint for country stats print(df.loc[0:5, &#39;country_name&#39;:&#39;deaths&#39;]) # show row 0 through 5 and columns country_name through deaths fetch() . country_name cases deaths 0 USA 82,649,779 1,018,316 1 India 43,057,545 522,193 2 Brazil 30,345,654 662,663 3 France 28,244,977 145,020 4 Germany 24,109,433 134,624 5 UK 21,933,206 173,352 . Hacks . Early Seed award . Add this Blog to you own Blogging site. | Have all lecture files saved to your files directory before Tech Talk starts. Have data.csv open in vscode. Don&#39;t tell anyone. Show to Teacher. | . AP Prep . Add this Blog to you own Blogging site. In the Blog add notes and observations on each code cell. | In blog add College Board practice problems for 2.3. | . The next 4 weeks, Teachers want you to improve your understanding of data. Look at the blog and others on Unit 2. Your intention is to find some things to differentiate your individual College Board project. . Create or Find your own dataset. The suggestion is to use a JSON file, integrating with your PBL project would be Amazing. . | When choosing a data set, think about the following... . Does it have a good sample size? | Is there bias in the data? | Does the data set need to be cleaned? | What is the purpose of the data set? | ... | . | Continue this Blog using Pandas extract info from that dataset (ex. max, min, mean, median, mode, etc.) . | . Hack Helpers . Here is how Mort started on this assignment by asking ChatGPT ... Regarding Python Pandas, what are some data sets that would be good for learning Pandas? . There are many data sets that are suitable for learning pandas, depending on your interests and the skills you want to develop. . Here are some suggestions... . Titanic Dataset:This is a classic dataset for data analysis and machine learning, and is often used as an introduction to pandas. The dataset contains information about passengers on the Titanic, including their demographics, ticket class, and survival status. | Iris Dataset: This is another classic dataset that is often used in machine learning and data analysis courses. The dataset contains information about iris flowers, including their sepal length, sepal width, petal length, and petal width. . | NBA Player Stats: This dataset contains information about NBA players, including their stats for various games, their positions, and their salaries. It is a great dataset for learning how to clean and manipulate data using pandas. . | Housing Prices Dataset: This dataset contains information about housing prices in a particular city or region, including variables such as the number of bedrooms, square footage, and price. It is a great dataset for learning how to manipulate and analyze numerical data using pandas. . | COVID-19 Dataset: This dataset contains information about the COVID-19 pandemic, including the number of cases, deaths, and recoveries in various countries and regions. It is a great dataset for learning how to manipulate and analyze time-series data using pandas. . | World Bank Dataset: This dataset contains information about economic indicators from various countries, such as GDP, population, and poverty rates. It is a great dataset for learning how to manipulate and analyze large datasets using pandas. . | . | . These are just a few examples of the many datasets that are suitable for learning pandas. The best dataset for you will depend on your interests and the specific skills you want to develop. . Follow up question, &quot;where can I find Titanic data set?&quot; . | The Titanic dataset is a popular dataset for data analysis and machine learning, and it can be found on various websites and data repositories. Here are a few places where you can find the Titanic dataset... . Kaggle:The Titanic dataset is available on Kaggle, which is a popular platform for data scientists and machine learning enthusiasts. You can download the dataset from the Kaggle website after creating an account. | UCI Machine Learning Repository: The Titanic dataset is also available on the UCI Machine Learning Repository, which is a collection of datasets that are commonly used for machine learning research. You can download the dataset from the UCI Machine Learning Repository website. . | Seaborn library: If you have the Seaborn library installed in your Python environment, you can load the Titanic dataset directly from the library using the following code: . import seaborn as sns titanic_data = sns.load_dataset(&#39;titanic&#39;) . | . | . Titanic Data . Look at a sample of data. . import seaborn as sns # Load the titanic dataset titanic_data = sns.load_dataset(&#39;titanic&#39;) print(&quot;Titanic Data&quot;) print(titanic_data.columns) # titanic data set print(titanic_data[[&#39;survived&#39;,&#39;pclass&#39;, &#39;sex&#39;, &#39;age&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;class&#39;, &#39;fare&#39;, &#39;embark_town&#39;]]) # look at selected columns . Titanic Data Index([&#39;survived&#39;, &#39;pclass&#39;, &#39;sex&#39;, &#39;age&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;fare&#39;, &#39;embarked&#39;, &#39;class&#39;, &#39;who&#39;, &#39;adult_male&#39;, &#39;deck&#39;, &#39;embark_town&#39;, &#39;alive&#39;, &#39;alone&#39;], dtype=&#39;object&#39;) survived pclass sex age sibsp parch class fare 0 0 3 male 22.0 1 0 Third 7.2500 1 1 1 female 38.0 1 0 First 71.2833 2 1 3 female 26.0 0 0 Third 7.9250 3 1 1 female 35.0 1 0 First 53.1000 4 0 3 male 35.0 0 0 Third 8.0500 .. ... ... ... ... ... ... ... ... 886 0 2 male 27.0 0 0 Second 13.0000 887 1 1 female 19.0 0 0 First 30.0000 888 0 3 female NaN 1 2 Third 23.4500 889 1 1 male 26.0 0 0 First 30.0000 890 0 3 male 32.0 0 0 Third 7.7500 embark_town 0 Southampton 1 Cherbourg 2 Southampton 3 Southampton 4 Southampton .. ... 886 Southampton 887 Southampton 888 Southampton 889 Cherbourg 890 Queenstown [891 rows x 9 columns] . Use Pandas to clean the data. Most analysis, like Machine Learning or even Pandas in general like data to be in standardized format. This is called &#39;Training&#39; or &#39;Cleaning&#39; data. . # Preprocess the data from sklearn.preprocessing import OneHotEncoder td = titanic_data td.drop([&#39;alive&#39;, &#39;who&#39;, &#39;adult_male&#39;, &#39;class&#39;, &#39;embark_town&#39;, &#39;deck&#39;], axis=1, inplace=True) td.dropna(inplace=True) td[&#39;sex&#39;] = td[&#39;sex&#39;].apply(lambda x: 1 if x == &#39;male&#39; else 0) td[&#39;alone&#39;] = td[&#39;alone&#39;].apply(lambda x: 1 if x == True else 0) # Encode categorical variables enc = OneHotEncoder(handle_unknown=&#39;ignore&#39;) enc.fit(td[[&#39;embarked&#39;]]) onehot = enc.transform(td[[&#39;embarked&#39;]]).toarray() cols = [&#39;embarked_&#39; + val for val in enc.categories_[0]] td[cols] = pd.DataFrame(onehot) td.drop([&#39;embarked&#39;], axis=1, inplace=True) td.dropna(inplace=True) print(td) . survived pclass sex age sibsp parch fare alone embarked_C 0 0 3 1 22.0 1 0 7.2500 0 0.0 1 1 1 0 38.0 1 0 71.2833 0 1.0 2 1 3 0 26.0 0 0 7.9250 1 0.0 3 1 1 0 35.0 1 0 53.1000 0 0.0 4 0 3 1 35.0 0 0 8.0500 1 0.0 .. ... ... ... ... ... ... ... ... ... 705 0 2 1 39.0 0 0 26.0000 1 0.0 706 1 2 0 45.0 0 0 13.5000 1 0.0 707 1 1 1 42.0 0 0 26.2875 1 0.0 708 1 1 0 22.0 0 0 151.5500 1 0.0 710 1 1 0 24.0 0 0 49.5042 1 1.0 embarked_Q embarked_S 0 0.0 1.0 1 0.0 0.0 2 0.0 1.0 3 0.0 1.0 4 0.0 1.0 .. ... ... 705 0.0 1.0 706 0.0 1.0 707 1.0 0.0 708 0.0 1.0 710 0.0 0.0 [564 rows x 11 columns] . The result of &#39;Training&#39; data is making it easier to analyze or make conclusions. In looking at the Titanic, as you clean you would probably want to make assumptions on likely chance of survival. . This would involve analyzing various factors (such as age, gender, class, etc.) that may have affected a person&#39;s chances of survival, and using that information to make predictions about whether an individual would have survived or not. . Data description:- Survival - Survival (0 = No; 1 = Yes). Not included in test.csv file. - Pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd) . Name - Name | Sex - Sex | Age - Age | Sibsp - Number of Siblings/Spouses Aboard | Parch - Number of Parents/Children Aboard | Ticket - Ticket Number | Fare - Passenger Fare | Cabin - Cabin | Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) | . | Perished Mean/Average . | . print(titanic_data.query(&quot;survived == 0&quot;).mean()) . survived 0.000000 pclass 2.464072 sex 0.844311 age 31.073353 sibsp 0.562874 parch 0.398204 fare 24.835902 alone 0.616766 embarked_C 0.185629 embarked_Q 0.038922 embarked_S 0.775449 dtype: float64 . Survived Mean/Average | . print(td.query(&quot;survived == 1&quot;).mean()) . survived 1.000000 pclass 1.878261 sex 0.326087 age 28.481522 sibsp 0.504348 parch 0.508696 fare 50.188806 alone 0.456522 embarked_C 0.152174 embarked_Q 0.034783 embarked_S 0.813043 dtype: float64 . Survived Max and Min Stats . print(td.query(&quot;survived == 1&quot;).max()) print(td.query(&quot;survived == 1&quot;).min()) . survived 1.0000 pclass 3.0000 sex 1.0000 age 80.0000 sibsp 4.0000 parch 5.0000 fare 512.3292 alone 1.0000 embarked_C 1.0000 embarked_Q 1.0000 embarked_S 1.0000 dtype: float64 survived 1.00 pclass 1.00 sex 0.00 age 0.75 sibsp 0.00 parch 0.00 fare 0.00 alone 0.00 embarked_C 0.00 embarked_Q 0.00 embarked_S 0.00 dtype: float64 . Machine Learning Visit Tutorials Point . Scikit-learn (Sklearn) is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python. . Description from ChatGPT. The Titanic dataset is a popular dataset for data analysis and machine learning. In the context of machine learning, accuracy refers to the percentage of correctly classified instances in a set of predictions. In this case, the testing data is a subset of the original Titanic dataset that the decision tree model has not seen during training......After training the decision tree model on the training data, we can evaluate its performance on the testing data by making predictions on the testing data and comparing them to the actual outcomes. The accuracy of the decision tree classifier on the testing data tells us how well the model generalizes to new data that it hasn&#39;t seen before......For example, if the accuracy of the decision tree classifier on the testing data is 0.8 (or 80%), this means that 80% of the predictions made by the model on the testing data were correct....Chance of survival could be done using various machine learning techniques, including decision trees, logistic regression, or support vector machines, among others. . | Code Below prepares data for further analysis and provides an Accuracy. IMO, you would insert a new passenger and predict survival. Datasets could be used on various factors like prediction if a player will hit a Home Run, or a Stock will go up or down. . Decision Trees, prediction by a piecewise constant approximation. | Logistic Regression, the probabilities describing the possible outcomes. | . | . from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score # Split arrays or matrices into random train and test subsets. X = td.drop(&#39;survived&#39;, axis=1) y = td[&#39;survived&#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Train a decision tree classifier dt = DecisionTreeClassifier() dt.fit(X_train, y_train) # Test the model y_pred = dt.predict(X_test) accuracy = accuracy_score(y_test, y_pred) print(&#39;DecisionTreeClassifier Accuracy:&#39;, accuracy) # Train a logistic regression model logreg = LogisticRegression() logreg.fit(X_train, y_train) # Test the model y_pred = logreg.predict(X_test) accuracy = accuracy_score(y_test, y_pred) print(&#39;LogisticRegression Accuracy:&#39;, accuracy) . DecisionTreeClassifier Accuracy: 0.7705882352941177 LogisticRegression Accuracy: 0.788235294117647 . /Users/johnmortensen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression n_iter_i = _check_optimize_result( .",
            "url": "https://xiaoa0.github.io/ds/2023/03/09/AP-unit2-3.html",
            "relUrl": "/2023/03/09/AP-unit2-3.html",
            "date": " • Mar 9, 2023"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://xiaoa0.github.io/ds/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a high school student taking the AP CSA course. This is a personal blog to store my work and document my learnings. .",
          "url": "https://xiaoa0.github.io/ds/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "",
          "content": "Hello! . This is an html page running with fastpages. .",
          "url": "https://xiaoa0.github.io/ds/hello.html",
          "relUrl": "/hello.html",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://xiaoa0.github.io/ds/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}