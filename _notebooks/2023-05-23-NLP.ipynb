{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Required Libraries\n",
    "Ensure that you have the necessary libraries installed. You'll need scikit-learn, numpy, and pandas, which can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xiaoa1/Library/Python/3.10/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xiaoa1/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn numpy pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "Import the required libraries in your Python script or Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Preprocess Data\n",
    "Load your labeled dataset into a pandas DataFrame. Preprocess the text data by cleaning and preparing it for analysis, including steps like removing punctuation, stopwords, and performing tokenization. Ensure that your DataFrame has two columns: \"text\" (containing the text data) and \"label\" (containing the corresponding labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>my new baby sat for two whole hours and didnt ...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>novelty gag toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31140</th>\n",
       "      <td>this is probably the best blood glucose meter ...</td>\n",
       "      <td>health personal care</td>\n",
       "      <td>medical supplies equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17172</th>\n",
       "      <td>the drakkar fragrance has been around for a ve...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>fragrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18957</th>\n",
       "      <td>i paid 70 for the dermanew microdermabrasion s...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>skin care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>we picked one of these up at a pet store earli...</td>\n",
       "      <td>pet supplies</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17160</th>\n",
       "      <td>the boys really enjoyed playing with this it i...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>dress up pretend play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35536</th>\n",
       "      <td>this coffee has very good flavor and reminds m...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>weve had the gate for about a year set between...</td>\n",
       "      <td>baby products</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23603</th>\n",
       "      <td>bought this mini staircase for my aging kitty ...</td>\n",
       "      <td>pet supplies</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17919</th>\n",
       "      <td>i like this product it seems to work very well...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>skin care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text   \n",
       "2594   my new baby sat for two whole hours and didnt ...  \\\n",
       "31140  this is probably the best blood glucose meter ...   \n",
       "17172  the drakkar fragrance has been around for a ve...   \n",
       "18957  i paid 70 for the dermanew microdermabrasion s...   \n",
       "7105   we picked one of these up at a pet store earli...   \n",
       "...                                                  ...   \n",
       "17160  the boys really enjoyed playing with this it i...   \n",
       "35536  this coffee has very good flavor and reminds m...   \n",
       "772    weve had the gate for about a year set between...   \n",
       "23603  bought this mini staircase for my aging kitty ...   \n",
       "17919  i like this product it seems to work very well...   \n",
       "\n",
       "                       Cat1                        Cat2  \n",
       "2594             toys games            novelty gag toys  \n",
       "31140  health personal care  medical supplies equipment  \n",
       "17172                beauty                   fragrance  \n",
       "18957                beauty                   skin care  \n",
       "7105           pet supplies                        cats  \n",
       "...                     ...                         ...  \n",
       "17160            toys games       dress up pretend play  \n",
       "35536  grocery gourmet food                   beverages  \n",
       "772           baby products                      safety  \n",
       "23603          pet supplies                        dogs  \n",
       "17919                beauty                   skin care  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/xiaoa1/VSCode/ds/_notebooks/data/train_40k.csv')\n",
    "\n",
    "df_val = pd.read_csv('/Users/xiaoa1/VSCode/ds/_notebooks/data/val_10k.csv')\n",
    "\n",
    "columns = ['Text', 'Cat1', 'Cat2']\n",
    "\n",
    "df = shuffle(df_original[columns])\n",
    "\n",
    "df.Cat1.value_counts()\n",
    "df.Cat2.value_counts()\n",
    "\n",
    "p = re.compile(r'[^\\w\\s]+')\n",
    "\n",
    "df['Text'] = [p.sub('', x) for x in df['Text'].tolist()]\n",
    "\n",
    "df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the Dataset\n",
    "Split your dataset into training and testing sets using train_test_split from scikit-learn. This ensures that you have data for training the model as well as evaluating its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = df.Text, df.Cat1, df.Cat2\n",
    "train_x, test_x, train_y, test_y, train_z, test_z = train_test_split(x, y, z, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Extraction\n",
    "Convert the text data into numerical feature vectors that can be used by machine learning algorithms. Use scikit-learn's CountVectorizer to convert text into a matrix of token counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,2), stop_words='english', sublinear_tf=True)),\n",
    "                     ('chi', SelectKBest(chi2, k=10000)),\n",
    "                     ('clf', LinearSVC(C=1.0, penalty='l1',max_iter=3000, dual=False))\n",
    "                    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training\n",
    "Choose a classification algorithm, such as Support Vector Machines (SVM), and train the model using the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_x, train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Evaluation\n",
    "Use the trained model to predict the labels for the test data, and evaluate its performance using accuracy or other suitable metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoa1/VSCode/ds/_notebooks/2023-05-23-NLP.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xiaoa1/VSCode/ds/_notebooks/2023-05-23-NLP.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39maccuracy score: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(model\u001b[39m.\u001b[39;49mscore(test_x, test_y, test_z)))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/pipeline.py:722\u001b[0m, in \u001b[0;36mPipeline.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     score_params[\u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sample_weight\n\u001b[0;32m--> 722\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mscore(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mscore_params)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:668\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:229\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     score \u001b[39m=\u001b[39m y_true \u001b[39m==\u001b[39m y_pred\n\u001b[0;32m--> 229\u001b[0m \u001b[39mreturn\u001b[39;00m _weighted_sum(score, sample_weight, normalize)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:139\u001b[0m, in \u001b[0;36m_weighted_sum\u001b[0;34m(sample_score, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_weighted_sum\u001b[39m(sample_score, sample_weight, normalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mif\u001b[39;00m normalize:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49maverage(sample_score, weights\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    140\u001b[0m     \u001b[39melif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(sample_score, sample_weight)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/function_base.py:551\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(scl \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m):\n\u001b[1;32m    548\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    549\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWeights sum to zero, can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be normalized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 551\u001b[0m     avg \u001b[39m=\u001b[39m avg_as_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmultiply(a, wgt,\n\u001b[1;32m    552\u001b[0m                       dtype\u001b[39m=\u001b[39;49mresult_dtype)\u001b[39m.\u001b[39;49msum(axis, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeepdims_kw) \u001b[39m/\u001b[39;49m scl\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m returned:\n\u001b[1;32m    555\u001b[0m     \u001b[39mif\u001b[39;00m scl\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m avg_as_array\u001b[39m.\u001b[39mshape:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "print('accuracy score: '+ str(model.score(test_x, test_y, test_z)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Prediction\n",
    "Once your model is trained and evaluated, you can use it to classify new, unseen text data by transforming the text into feature vectors using the CountVectorizer and then applying the trained model's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health personal care']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
