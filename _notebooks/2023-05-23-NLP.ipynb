{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project outline courtesy of ChatGPT, code and revisions by xiaoa0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Required Libraries\n",
    "Ensure that you have the necessary libraries installed. You'll need scikit-learn, numpy, and pandas, which can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xiaoa1/Library/Python/3.10/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xiaoa1/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn numpy pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "Import the required libraries in your Python script or Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Preprocess Data\n",
    "Load your labeled dataset into a pandas DataFrame. Preprocess the text data by cleaning and preparing it for analysis, including steps like removing punctuation, stopwords, and performing tokenization. Ensure that your DataFrame has two columns: \"text\" (containing the text data) and \"label\" (containing the corresponding labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33490</th>\n",
       "      <td>i dont know why you would buy anything else un...</td>\n",
       "      <td>pet supplies</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34087</th>\n",
       "      <td>after trying out about 12 different ones i cam...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>fragrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>i bought these for my 7 year old nephew for ch...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>electronics for kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20015</th>\n",
       "      <td>my sons often raid my cabinets for my sushi no...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "      <td>snack food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>not only is this product actually good for you...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>skin care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>this puzzle is well worth buying as it is quit...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>puzzles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11302</th>\n",
       "      <td>this is my first epilator so i dont have much ...</td>\n",
       "      <td>health personal care</td>\n",
       "      <td>personal care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190</th>\n",
       "      <td>very cute a little smaller than i expected but...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>baby toddler toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20772</th>\n",
       "      <td>works well with or without an ice pack there w...</td>\n",
       "      <td>baby products</td>\n",
       "      <td>feeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29607</th>\n",
       "      <td>straight up youre probably not getting enough ...</td>\n",
       "      <td>health personal care</td>\n",
       "      <td>nutrition wellness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text   \n",
       "33490  i dont know why you would buy anything else un...  \\\n",
       "34087  after trying out about 12 different ones i cam...   \n",
       "571    i bought these for my 7 year old nephew for ch...   \n",
       "20015  my sons often raid my cabinets for my sushi no...   \n",
       "4134   not only is this product actually good for you...   \n",
       "...                                                  ...   \n",
       "263    this puzzle is well worth buying as it is quit...   \n",
       "11302  this is my first epilator so i dont have much ...   \n",
       "21190  very cute a little smaller than i expected but...   \n",
       "20772  works well with or without an ice pack there w...   \n",
       "29607  straight up youre probably not getting enough ...   \n",
       "\n",
       "                       Cat1                  Cat2  \n",
       "33490          pet supplies                  dogs  \n",
       "34087                beauty             fragrance  \n",
       "571              toys games  electronics for kids  \n",
       "20015  grocery gourmet food            snack food  \n",
       "4134                 beauty             skin care  \n",
       "...                     ...                   ...  \n",
       "263              toys games               puzzles  \n",
       "11302  health personal care         personal care  \n",
       "21190            toys games     baby toddler toys  \n",
       "20772         baby products               feeding  \n",
       "29607  health personal care    nutrition wellness  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/xiaoa1/VSCode/ds/_notebooks/data/train_40k.csv')\n",
    "\n",
    "df_val = pd.read_csv('/Users/xiaoa1/VSCode/ds/_notebooks/data/val_10k.csv')\n",
    "\n",
    "columns = ['Text', 'Cat1', 'Cat2']\n",
    "\n",
    "df = shuffle(df_original[columns])\n",
    "\n",
    "df.Cat1.value_counts()\n",
    "df.Cat2.value_counts()\n",
    "\n",
    "p = re.compile(r'[^\\w\\s]+')\n",
    "\n",
    "df['Text'] = [p.sub('', x) for x in df['Text'].tolist()]\n",
    "\n",
    "df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the Dataset\n",
    "Split your dataset into training and testing sets using train_test_split from scikit-learn. This ensures that you have data for training the model as well as evaluating its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = df.Text, df.Cat1, df.Cat2\n",
    "train_x, test_x, train_y, test_y, train_z, test_z = train_test_split(x, y, z, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Extraction\n",
    "Convert the text data into numerical feature vectors that can be used by machine learning algorithms. Use scikit-learn's CountVectorizer to convert text into a matrix of token counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,2), stop_words='english', sublinear_tf=True)),\n",
    "                     ('chi', SelectKBest(chi2, k=10000)),\n",
    "                     ('clf', LinearSVC(C=1.0, penalty='l1',max_iter=3000, dual=False))\n",
    "                    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training\n",
    "Choose a classification algorithm, such as Support Vector Machines (SVM), and train the model using the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pipeline.fit() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoa1/VSCode/ds/_notebooks/2023-05-23-NLP.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xiaoa1/VSCode/ds/_notebooks/2023-05-23-NLP.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit(train_x, train_y, train_z)\n",
      "\u001b[0;31mTypeError\u001b[0m: Pipeline.fit() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_x, train_y, train_z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Evaluation\n",
    "Use the trained model to predict the labels for the test data, and evaluate its performance using accuracy or other suitable metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.843375\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: '+ str(model.score(test_x, test_y, test_z)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Prediction\n",
    "Once your model is trained and evaluated, you can use it to classify new, unseen text data by transforming the text into feature vectors using the CountVectorizer and then applying the trained model's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beauty']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['bright color and good texture']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
